#summary Testing the RDF Pipeline framework
<wiki:toc max_depth="1" />

= Introduction =
The RDF Pipeline framework has a regression test suite in RDF-Pipeline/t .  Since it runs as a mod_perl2 module in Apache2, the RDF Pipeline framework must be properly installed (as a mod_perl2 module) before the test suite can be run.  Once installed, the test suite may be run by issuing the following command from the RDF-Pipeline module directory:
{{{
  make test
}}}

= Environment variables =
The test suite depends on two directories, which must be specified in the following environment variables (normally set by set_env.sh):
  * *$RDF_PIPELINE_WWW_DIR* -- The Apache DOCUMENT_ROOT for the RDF Pipeline framework.
  * *$RDF_PIPELINE_DEV_DIR* -- The top level RDF Pipeline development directory, which contains the RDF::Pipeline module directory "RDF-Pipeline".
These variables are normally set by $RDF_PIPELINE_DEV_DIR/set_env.sh, which will also add the test scripts to your $PATH if our "source" it:
{{{
cd $RDF_PIPELINE_DEV_DIR
. set_env.sh
}}}
You should customize set_env.sh according to your site.

= Test suite conventions =
Each test is in a numbered directory RDF-Pipeline/t/nnnn (where nnnn is a four-digit number that _must_ start with 0) and contains the following subdirectories or files.  All are optional unless noted:
  * *setup-files* -- This directory contains a snapshot of the $RDF_PIPELINE_WWW_DIR contents that should be used when running the test.  If it does not exist, the current $RDF_PIPELINE_WWW_DIR contents will be used.
  * *test-script* -- (REQUIRED) The script that runs the test.  If it returns 0, then the test passes.  Otherwise, the test fails.  The default test-script generated by add-test.perl will run pipeline-request.perl to invoke the test and capture the results, and then it will compare the result-files with the expected-files to determine whether the test passed or failed.  However, it can be modified to do whatever you need to do.
  * *result-files* -- If used by test-script, this directory will contain a snapshot of the $RDF_PIPELINE_WWW_DIR contents as it existed after running the test.  
  * *expected-files* -- If used by test-script, this directory will contain a snapshot of the $RDF_PIPELINE_WWW_DIR contents as it _should_ be after successfully running the test.  If the result-files are the same as the expected-files then the test passes, otherwise it fails.

A test usually issues one or more HTTP requests against the Apache instance that is hosting the pipeline.  Hence, each test is normally driven by one or more URLs.  To facilitate regression testing, a test should write all information that is relevant to determining whether it passed, to the $RDF_PIPELINE_WWW_DIR/test directory, as this is what run-test.perl expects.  By default this will include:
  * *apacheAccess.log* -- The Apache "access.log" file (excerpted and filtered through RDF-Pipeline/t/stripdates.perl to remove irrelevant detail)
  * *apacheError.log* -- The Apache "error.log" file (excerpted and filtered through RDF-Pipeline/t/filterlog.perl to remove irrelevant detail)
  * *testout* -- The concatenated results (filtered through RDF-Pipeline/t/stripdates.perl) of running 'curl -i' on the test URLs.  This includes both the headers and the content that were returned.

= Adding a new test =
<ol>
<li>Configure a pipeline as needed for the test, so that the content of $RDF_PIPELINE_WWW_DIR reflects the desired initial state _prior_ to running the new test.  Do not place anything in the $RDF_PIPELINE_WWW_DIR/test directory, as this will be entirely cleared out just before the test is run.
</li>
<li>Run the command:
  {{{
  add-test.perl URL
  }}}
where URL is the URL to be requested from the pipeline.  This will generate a new, numbered test directory containing:
    * *setup-files* -- A snapshot of the current the $RDF_PIPELINE_WWW_DIR directory.  You can customize its content as appropriate, such as deleting files that are not needed in setting up for your test.
    * *test-script* -- Initial script that you can customize as needed for this test.
After creating the above files/directories, add-test.perl will invoke run-test.perl to execute the test, which in turn will create the following directory:
    * *result-files* -- A snapshot of the $RDF_PIPELINE_WWW_DIR directory after running the test.
and it will then try to compare the result-files with the expected-files, thus causing the test to initially fail (as it should) because the test will not have any expected-files yet.
</li>
<li>If necessary, you may run the test as many times as you need while debugging, using "`./run-test.perl [nnnn]`" or "`./run-test.perl -c [nnnn]`", as described below under "Running a test", *restarting Apache each time you have modified anything*.  Bear in mind that the result-files are replaced each time the test is run (and the $RDF_PIPELINE_WWW_DIR files will be also if you used the -c option).
</li>
<li>After you are convinced that the result-files are correct, run
    {{{
    accept-test.perl [nnnn]
    }}}
to cause the current result-files to be saved as expected-files.  This should cause the test to pass the next time you run it.  If you omit the test number nnnn, it will default to the highest numbered test, which will normally be the one you just added.
</li>
</ol>

= Running a test =
Before running a test it is best to restart Apache, to be sure that it uses the latest version of whatever you are working on.  This must be done as root:
{{{
    # apache2ctl stop ; sleep 5 ; apache2ctl start
}}}

To run one test (or more) without using "make test":
    {{{
    run-test.perl [-c] [nnnn] ...
    }}}
where nnnn is the test's numbered directory, and defaults to the highest numbered test if not specified.  This does the following for each test directory:
  * If there are setup-files, then the existing $RDF_PIPELINE_WWW_DIR files are deleted (after saving $RDF_PIPELINE_WWW_DIR to "$RDF_PIPELINE_WWW_DIR"-SAVE if -c is not specified) and replaced with setup-files.
  * The test-script is run as `./test-script '$TESTDIR' '$RDF_PIPELINE_WWW_DIR'` , where $TESTDIR is the full path of the current test directory nnnn.  The default test-script that is generated by add-test.perl saves the test results (an abridged snapshot of $RDF_PIPELINE_WWW_DIR) into result-files, and then compares them with the expected-files.  Iff they match, then test-script exits with 0 status to indicate that the test passed. 
  * The original $RDF_PIPELINE_WWW_DIR files are restored from "$RDF_PIPELINE_WWW_DIR"-SAVE if -c was not specified.

Finally, run-test.perl silently exits with 0 status if the test passed, or it noisily prints an error and exits with non-zero status if the test failed.

The -c option ("clobber") tells run-test.perl to leave the $RDF_PIPELINE_WWW_DIR files in their final state after running the test, instead of restoring them from a saved copy.  I.e., the previous $RDF_PIPELINE_WWW_DIR files get clobbered.  This is particularly useful when you plan to add a new test (using add-test.perl) that should continue from the state where the the current test left off.  

= Diagnosing a failed test =
To help figure out why a test failed, cd into that test directory and do:
{{{
  diff -r -x lm -x ont -x '.*' expected-files result-files
}}}
See the code in $RDF_PIPELINE_DEV_DIR/RDF-Pipeline/t/helpers/compare-results.perl (though you probably won't want to use the -q option that it uses).

= Accepting test results =
If you need to update the expected-files for one or more tests (e.g., because a code change has caused the result-files to no longer match the expected-files), then *once you are certain that the current result-files are correct*, you can do
{{{
  accept-test.perl [-s][nnnn] ...
}}}
to delete the existing expected-files and copy the current result-files to the expected-files.

The "`-s`" option will cause accept-test.perl to attempt to add the test to subversion.

= Deleting a test = 
Delete that particular subdirectory, e.g., 0003.

= Other helper scripts =
The $RDF_PIPELINE_DEV_DIR/RDF-Pipeline/t/helpers directory contains some additional helper scripts that you may find useful.  They are used by the other test scripts in $RDF_PIPELINE_DEV_DIR/RDF-Pipeline/t , so be sure you check how they are used before modifying them.
  * *pipeline-request [GET/HEAD] URL*
    Use curl to invoke URL using the method specified (or GET, if no method is specified), saving the resulting headers and content to $RDF_PIPELINE_WWW_DIR/test/testout .  For example, "`pipeline-request HEAD http://localhost/node/foo`" will use curl to issue a HEAD request to http://localhost/node/foo .
  * *filterlog.perl* -- A script for filtering Apache log files.
  * *stripdates.perl* -- A script for replacing datetimes with some datetime constants.
  * *copy-dir.perl sourceDir destDir* -- Recursively copies sourceDir to destDir, excluding hidden (`.*`) files.
  * *compare-results.perl expected-files result-files* -- Recursively compares expected-files with result-files (excluding "lm", "ont" and hidden subdirectories/files), returning 0 iff they are the same.

= Subversion (svn) errors =
Because subversion places hidden ".svn" files in directories that are under its control, these test scripts can cause some hassle in working with subversion.  To avoid copying the ".svn" files, the test scripts above delete all hidden files after copying a directory.  (This is done by helpers/copy-result-files.perl .)  However, this has the downside that when a directory was rightfully under subversion control, but it is replaced by one of these scripts, the ".svn" files will no longer be in it, causing subversion to complain like: *"svn: Failed to add directory 'www/test': an unversioned directory of the same name already exists"*.  To correct this problem, use the "`--force`" svn option, such as:
{{{
cd $RDF_PIPELINE_DEV_DIR
svn update --force
}}}